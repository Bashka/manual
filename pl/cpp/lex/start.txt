====== Структура ======
Для компиляции лексического анализатора используется файл следующей структуры:
<file cpp file.l>
%{
Заголовки
%}
%%
Тело
%%
</file>
Блок заголовков содержит код на языке C, который копируется в результирующий файл лексера.

Блок тела содержит определения токенов, которые может определить результирующий лексер. Этот блок имеет следующую структуру:
<code cpp>
регуряноеВыражение  обработчик
</code>
Как видно из примера, для обнаружения токенов используются регулярные выражения. В качестве обработчика здесь может выступать любой код на языке C.

Пример:
<code cpp>
%{
#include <stdio.h>
%}
%%
function!?	printf("FUNCTION");
\{	printf("BLOCK_START");
\}	printf("BLOCK_END");
\(	printf("ARGS_START");
\)	printf("ARGS_END");
([a-z]:)?[A-Za-z_][A-Za-z0-9_]*	printf("NAME");
%%
</code>

====== Компиляция ======
Утилита лексера компилируется в два шага:
  - С помощью утилиты ''lex'' из файла описания токенов (файл с расширением ''*.l'', структура которого рассматривалась в предыдущем разделе) создается программа на языке C в виде файла с именем ''файлТокенов.yy.l'';
  - С помощью компилятора языка C и библиотеки ''l'' полученная на предыдущем шаге программа компилируется в исполняемый код.
<code bash>
cc lexer.yy.l -ll
</code>

====== Выполнение ======
Полученный после компиляции лексический анализатор представляет простую утилиту, принимающую в стандартном потоке ввода данные и выполняющую некоторые операции (на пример возврате значений) при нахождении токенов. Для дальнейшей обработки потока токенов, получаемого при лексическом аналезе, используется синтаксический анализатор.
